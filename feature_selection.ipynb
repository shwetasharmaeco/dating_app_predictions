{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shwetasharma1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shwetasharma1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use(\"ggplot\")\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "np.random.seed(27)\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopwords_ = set(stopwords.words('english'))\n",
    "punctuation_ = set(string.punctuation)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer_snowball = SnowballStemmer('english')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer_porter = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
       "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
       "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
       "       'religion', 'sex', 'sign', 'smokes', 'speaks', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diet column has more than half nans. will not be using it.\n",
    "#income had many negative values. dropping tyhis column as well\n",
    "# users_no_na.groupby([\"ethnicity\"]).size()\n",
    "\n",
    "users = pd.read_csv(\"./data/profiles.csv\")\n",
    "users_no_na = users[users[\"drugs\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "col_lst = ['essay0','essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7','essay8', 'essay9']\n",
    "\n",
    "for col in col_lst:\n",
    "    users_no_na[col] = users_no_na[col].fillna(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "users_no_na[\"essay\"] = users_no_na[\"essay0\"] + users_no_na[\"essay1\"] + users_no_na[\"essay2\"] + users_no_na[\"essay3\"] + users_no_na[\"essay4\"] + users_no_na[\"essay5\"] + users_no_na[\"essay6\"] + users_no_na[\"essay7\"] + users_no_na[\"essay8\"] + users_no_na[\"essay9\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        about me:<br />\\n<br />\\ni would love to think...\n",
       "1        i am a chef: this is what that means.<br />\\n1...\n",
       "4        hey how's it going? currently vague on the pro...\n",
       "6        life is about the little things. i love to lau...\n",
       "7        writing. meeting new people, spending time wit...\n",
       "                               ...                        \n",
       "59940    real deal: i am sensitive (sorry, tears includ...\n",
       "59941    vibrant, expressive, caring optimist. i love b...\n",
       "59942    i'm nick.<br />\\ni never know what to write ab...\n",
       "59943    hello! i enjoy traveling, watching movies, and...\n",
       "59944    \"all i have in this world are my balls and my ...\n",
       "Name: essay, Length: 45866, dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_no_na[\"essay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    clean the text data: split the text, remove the redundant signs and words.\n",
    "    '''\n",
    "    text = text.replace('<br />', ' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    words = nltk.word_tokenize(text)   #split the text into words\n",
    "    words = [word for word in words if word.isalpha()]    #remove the non-alphabetic signs\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = [word for word in words if word not in set(stop_words)]   #remove the stop words\n",
    "    return words\n",
    "\n",
    "def clean_text_column(df, col_name):\n",
    "    '''\n",
    "    input a dataframe and one of its column, the function clean the text within\n",
    "    the column.\n",
    "    '''\n",
    "    df_ = df[df[col_name].notnull()]\n",
    "    df[col_name] = df_.apply(lambda row: clean_text(row[col_name]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "clean_text_column(users_no_na, 'essay')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [would, love, think, kind, intellectual, eithe...\n",
       "1    [chef, means, workaholic, love, cook, regardle...\n",
       "4    [hey, going, currently, vague, profile, know, ...\n",
       "6    [life, little, things, love, laugh, easy, one,...\n",
       "7    [writing, meeting, new, people, spending, time...\n",
       "Name: essay, dtype: object"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_no_na[\"essay\"].head()\n",
    "# users_no_na[\"essay\"] = users_no_na[\"essay\"].fillna(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        would, love, think, kind, intellectual, either...\n",
       "1        chef, means, workaholic, love, cook, regardles...\n",
       "4        hey, going, currently, vague, profile, know, c...\n",
       "6        life, little, things, love, laugh, easy, one, ...\n",
       "7        writing, meeting, new, people, spending, time,...\n",
       "                               ...                        \n",
       "59940    real, deal, sensitive, sorry, tears, included,...\n",
       "59941    vibrant, expressive, caring, optimist, love, p...\n",
       "59942    nick, never, know, write, sure, hands, souther...\n",
       "59943    hello, enjoy, traveling, watching, movies, han...\n",
       "59944    world, balls, integrity, one, take, either, aw...\n",
       "Name: essay, Length: 45866, dtype: object"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "users_no_na[\"essay\"] = users_no_na[\"essay\"].apply(lambda x: \", \".join(x))\n",
    "users_no_na[\"essay\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_accents(input_str):\n",
    "    '''\n",
    "    This function is to remove the accents\n",
    "    '''\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode()\n",
    "\n",
    "def remove_http(sentences):\n",
    "    '''\n",
    "    remove the URLs in the text\n",
    "    '''\n",
    "    sentences_ = []\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "        sentences_.append(sentence)\n",
    "    return [sent for sent in sentences_ if not sent in {\"\", \"'\"}]\n",
    "\n",
    "def filter_tokens(sentence):\n",
    "    '''\n",
    "    This is to remove the stop words. Update the stop words in set stopwords2\n",
    "    '''\n",
    "    stopwords1 = set(stopwords.words('english'))\n",
    "    stopwords2 = {\"\\'s\",\"\\'ve\",\"\\'re\", \"n't\", 'INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "                  'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ', 'infj', 'entp','intp','intj',\n",
    "                  'entj','enfj','infp', 'enfp','isfp','istp','isfj','istj','estp','esfp','estj','esfj'}\n",
    "    stopwords_ = stopwords1.union(stopwords2)\n",
    "    \n",
    "    punctuation_ = set(string.punctuation)\n",
    "    return([w for w in sentence if not w in stopwords_ and not w in punctuation_])\n",
    "\n",
    "def remove_digits(sentences):\n",
    "    '''\n",
    "    remove the numbers in the text\n",
    "    '''\n",
    "    sentences_ = []\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub(r'[^a-zA-Z]+', ' ', sentence)\n",
    "        sentences_.append(sentence)\n",
    "    return [sent for sent in sentences_ if not sent in {\"\", \"'\"}]\n",
    "\n",
    "def lemm_and_stem(sentences):\n",
    "    '''\n",
    "    lemmatizing and stemming the words\n",
    "    '''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    output = []\n",
    "    for word_list in sentences:\n",
    "        lemmatized_words = [lemmatizer.lemmatize(w) for w in word_list]\n",
    "        stemmed_words = ' '.join([stemmer.stem(w) for w in lemmatized_words])\n",
    "        output.append(stemmed_words)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(input_str):\n",
    "    accent_removed=remove_accents(input_str) #remove the accent\n",
    "    sentences = accent_removed.split('|||') #split the string and get sentences\n",
    "    removed_http = remove_http(sentences)\n",
    "    removed_digits = remove_digits(removed_http)\n",
    "    tokens = [sent for sent in map(word_tokenize, removed_digits)]\n",
    "    tokens_lower = [[word.lower() for word in sentence]\n",
    "                 for sentence in tokens]\n",
    "    \n",
    "    tokens_filtered = list(map(filter_tokens, tokens_lower))\n",
    "    tokens_lemms = lemm_and_stem(tokens_filtered)\n",
    "\n",
    "    return tokens_lemms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "users_no_na[\"essay\"]=  users_no_na[\"essay\"].apply(lambda x: clean_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "users_no_na[\"essay\"] = users_no_na[\"essay\"].apply(lambda x: x[0] if x !=[] else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "      <th>essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>would love think kind intellectu either dumbes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "      <td>chef mean workahol love cook regardless whethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>hey go current vagu profil know come soon look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>fit</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>life is about the little things. i love to lau...</td>\n",
       "      <td>digging up buried treasure</td>\n",
       "      <td>frolicking&lt;br /&gt;\\nwitty banter&lt;br /&gt;\\nusing my...</td>\n",
       "      <td>i am the last unicorn</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>virgo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>life littl thing love laugh easi one find beau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td></td>\n",
       "      <td>writing. meeting new people, spending time wit...</td>\n",
       "      <td>remembering people's birthdays, sending cards,...</td>\n",
       "      <td>i'm rather approachable (a byproduct of being ...</td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but wants them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>christianity</td>\n",
       "      <td>f</td>\n",
       "      <td>sagittarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english, spanish (okay)</td>\n",
       "      <td>single</td>\n",
       "      <td>write meet new peopl spend time friend see fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59940</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on masters program</td>\n",
       "      <td>real deal: i am sensitive (sorry, tears includ...</td>\n",
       "      <td>right now...watching 'celebrity rehab' and com...</td>\n",
       "      <td>eating chocolate and doing pilates (usually no...</td>\n",
       "      <td>my hair? eyes? height? curves? dk....my caring...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>f</td>\n",
       "      <td>sagittarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), french, farsi</td>\n",
       "      <td>single</td>\n",
       "      <td>real deal sensit sorri tear includ move sf bay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>vibrant, expressive, caring optimist. i love b...</td>\n",
       "      <td>the happiest times have been when life came to...</td>\n",
       "      <td>i make an outstanding osso bucco. i am also ve...</td>\n",
       "      <td>i am told that people notice my smile, eyes an...</td>\n",
       "      <td>...</td>\n",
       "      <td>has kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>has dogs</td>\n",
       "      <td>catholicism but not too serious about it</td>\n",
       "      <td>f</td>\n",
       "      <td>cancer and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>vibrant express care optimist love peopl trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i'm nick.&lt;br /&gt;\\ni never know what to write ab...</td>\n",
       "      <td>currently finishing school for film production...</td>\n",
       "      <td>&lt;a class=\"ilink\" href=\"/interests?i=filmmaking...</td>\n",
       "      <td>dude, i don't know.</td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t have kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>m</td>\n",
       "      <td>leo but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "      <td>single</td>\n",
       "      <td>nick never know write sure hand southern calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>hello! i enjoy traveling, watching movies, and...</td>\n",
       "      <td>i'm a civil engineer, who enjoys helping the c...</td>\n",
       "      <td>- looking at things objectively&lt;br /&gt;\\n- getti...</td>\n",
       "      <td>i'm quiet until i get used to the environment ...</td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t have kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>christianity but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>sagittarius but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "      <td>single</td>\n",
       "      <td>hello enjoy travel watch movi hang friend rule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>\"all i have in this world are my balls and my ...</td>\n",
       "      <td>following my dreams...&lt;br /&gt;\\n\"you got a dream...</td>\n",
       "      <td>listening</td>\n",
       "      <td>it used to be the hair until i mowed it off bu...</td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but wants them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>leo and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>trying to quit</td>\n",
       "      <td>english (fluently), spanish (poorly), chinese ...</td>\n",
       "      <td>single</td>\n",
       "      <td>world ball integr one take either away linda d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45866 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       body_type               diet      drinks      drugs  \\\n",
       "0       22  a little extra  strictly anything    socially      never   \n",
       "1       35         average       mostly other       often  sometimes   \n",
       "4       29        athletic                NaN    socially      never   \n",
       "6       32             fit  strictly anything    socially      never   \n",
       "7       31         average    mostly anything    socially      never   \n",
       "...    ...             ...                ...         ...        ...   \n",
       "59940   31             NaN                NaN    socially      never   \n",
       "59941   59             NaN                NaN    socially      never   \n",
       "59942   24             fit    mostly anything       often  sometimes   \n",
       "59943   42         average    mostly anything  not at all      never   \n",
       "59944   27        athletic    mostly anything    socially      often   \n",
       "\n",
       "                               education  \\\n",
       "0          working on college/university   \n",
       "1                  working on space camp   \n",
       "4      graduated from college/university   \n",
       "6      graduated from college/university   \n",
       "7      graduated from college/university   \n",
       "...                                  ...   \n",
       "59940         working on masters program   \n",
       "59941  graduated from college/university   \n",
       "59942      working on college/university   \n",
       "59943     graduated from masters program   \n",
       "59944      working on college/university   \n",
       "\n",
       "                                                  essay0  \\\n",
       "0      about me:<br />\\n<br />\\ni would love to think...   \n",
       "1      i am a chef: this is what that means.<br />\\n1...   \n",
       "4      hey how's it going? currently vague on the pro...   \n",
       "6      life is about the little things. i love to lau...   \n",
       "7                                                          \n",
       "...                                                  ...   \n",
       "59940  real deal: i am sensitive (sorry, tears includ...   \n",
       "59941  vibrant, expressive, caring optimist. i love b...   \n",
       "59942  i'm nick.<br />\\ni never know what to write ab...   \n",
       "59943  hello! i enjoy traveling, watching movies, and...   \n",
       "59944  \"all i have in this world are my balls and my ...   \n",
       "\n",
       "                                                  essay1  \\\n",
       "0      currently working as an international agent fo...   \n",
       "1      dedicating everyday to being an unbelievable b...   \n",
       "4                             work work work work + play   \n",
       "6                             digging up buried treasure   \n",
       "7      writing. meeting new people, spending time wit...   \n",
       "...                                                  ...   \n",
       "59940  right now...watching 'celebrity rehab' and com...   \n",
       "59941  the happiest times have been when life came to...   \n",
       "59942  currently finishing school for film production...   \n",
       "59943  i'm a civil engineer, who enjoys helping the c...   \n",
       "59944  following my dreams...<br />\\n\"you got a dream...   \n",
       "\n",
       "                                                  essay2  \\\n",
       "0      making people laugh.<br />\\nranting about a go...   \n",
       "1      being silly. having ridiculous amonts of fun w...   \n",
       "4      creating imagery to look at:<br />\\nhttp://bag...   \n",
       "6      frolicking<br />\\nwitty banter<br />\\nusing my...   \n",
       "7      remembering people's birthdays, sending cards,...   \n",
       "...                                                  ...   \n",
       "59940  eating chocolate and doing pilates (usually no...   \n",
       "59941  i make an outstanding osso bucco. i am also ve...   \n",
       "59942  <a class=\"ilink\" href=\"/interests?i=filmmaking...   \n",
       "59943  - looking at things objectively<br />\\n- getti...   \n",
       "59944                                          listening   \n",
       "\n",
       "                                                  essay3  ...  \\\n",
       "0      the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                         ...   \n",
       "4                i smile a lot and my inquisitive nature  ...   \n",
       "6                                  i am the last unicorn  ...   \n",
       "7      i'm rather approachable (a byproduct of being ...  ...   \n",
       "...                                                  ...  ...   \n",
       "59940  my hair? eyes? height? curves? dk....my caring...  ...   \n",
       "59941  i am told that people notice my smile, eyes an...  ...   \n",
       "59942                                dude, i don't know.  ...   \n",
       "59943  i'm quiet until i get used to the environment ...  ...   \n",
       "59944  it used to be the hair until i mowed it off bu...  ...   \n",
       "\n",
       "                                          offspring orientation  \\\n",
       "0      doesn&rsquo;t have kids, but might want them    straight   \n",
       "1      doesn&rsquo;t have kids, but might want them    straight   \n",
       "4                                               NaN    straight   \n",
       "6                                               NaN    straight   \n",
       "7           doesn&rsquo;t have kids, but wants them    straight   \n",
       "...                                             ...         ...   \n",
       "59940                                           NaN    straight   \n",
       "59941                                      has kids    straight   \n",
       "59942                       doesn&rsquo;t have kids    straight   \n",
       "59943                       doesn&rsquo;t have kids    straight   \n",
       "59944       doesn&rsquo;t have kids, but wants them    straight   \n",
       "\n",
       "                            pets                                   religion  \\\n",
       "0      likes dogs and likes cats      agnosticism and very serious about it   \n",
       "1      likes dogs and likes cats   agnosticism but not too serious about it   \n",
       "4      likes dogs and likes cats                                        NaN   \n",
       "6      likes dogs and likes cats                                        NaN   \n",
       "7      likes dogs and likes cats                               christianity   \n",
       "...                          ...                                        ...   \n",
       "59940                 likes dogs                                agnosticism   \n",
       "59941                   has dogs   catholicism but not too serious about it   \n",
       "59942  likes dogs and likes cats                                agnosticism   \n",
       "59943                        NaN  christianity but not too serious about it   \n",
       "59944  likes dogs and likes cats   agnosticism but not too serious about it   \n",
       "\n",
       "      sex                                      sign          smokes  \\\n",
       "0       m                                    gemini       sometimes   \n",
       "1       m                                    cancer              no   \n",
       "4       m                                  aquarius              no   \n",
       "6       f                                     virgo             NaN   \n",
       "7       f                               sagittarius              no   \n",
       "...    ..                                       ...             ...   \n",
       "59940   f                               sagittarius              no   \n",
       "59941   f  cancer and it&rsquo;s fun to think about              no   \n",
       "59942   m           leo but it doesn&rsquo;t matter              no   \n",
       "59943   m   sagittarius but it doesn&rsquo;t matter              no   \n",
       "59944   m     leo and it&rsquo;s fun to think about  trying to quit   \n",
       "\n",
       "                                                  speaks  status  \\\n",
       "0                                                english  single   \n",
       "1      english (fluently), spanish (poorly), french (...  single   \n",
       "4                                                english  single   \n",
       "6                                                english  single   \n",
       "7                                english, spanish (okay)  single   \n",
       "...                                                  ...     ...   \n",
       "59940                  english (fluently), french, farsi  single   \n",
       "59941                                            english  single   \n",
       "59942                                 english (fluently)  single   \n",
       "59943                                 english (fluently)  single   \n",
       "59944  english (fluently), spanish (poorly), chinese ...  single   \n",
       "\n",
       "                                                   essay  \n",
       "0      would love think kind intellectu either dumbes...  \n",
       "1      chef mean workahol love cook regardless whethe...  \n",
       "4      hey go current vagu profil know come soon look...  \n",
       "6      life littl thing love laugh easi one find beau...  \n",
       "7      write meet new peopl spend time friend see fil...  \n",
       "...                                                  ...  \n",
       "59940  real deal sensit sorri tear includ move sf bay...  \n",
       "59941  vibrant express care optimist love peopl trave...  \n",
       "59942  nick never know write sure hand southern calif...  \n",
       "59943  hello enjoy travel watch movi hang friend rule...  \n",
       "59944  world ball integr one take either away linda d...  \n",
       "\n",
       "[45866 rows x 32 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tfidf_matrix = tfidf.fit_transform(users_no_na.essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.0836187 0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# print(sorted(tfidf.vocabulary_))\n",
    "print(document_tfidf_matrix.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtm = pd.DataFrame(document_tfidf_matrix.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# rf_data = users_no_na[[\"age\", \"drinks\", \"education\", \"ethnicity\", \"orientation\", \"sex\", \"smokes\", \"religion\" ,\"essay\",\"drugs\"]]\n",
    "# rf_data = users_no_na[[\"drinks\",\"smokes\", \"drugs\"]]\n",
    "\n",
    "rf_data[\"drugs\"] = rf_data[\"drugs\"].replace([\"never\",\"sometimes\", \"often\"], [0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([users_no_na, data_dtm], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ethnicity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ethnicity'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f44b0e37c5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# putting different ethnicities in wider buckets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ethnicity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ethnicity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"other\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ethnicity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'asian'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ethnicity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'asian'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ethnicity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'indian'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ethnicity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'asian'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ethnicity'"
     ]
    }
   ],
   "source": [
    "# putting different ethnicities in wider buckets\n",
    "\n",
    "rf_data[\"ethnicity\"] = rf_data[\"ethnicity\"].fillna(\"other\")\n",
    "rf_data.loc[rf_data['ethnicity'].str.contains('asian',), 'ethnicity'] = 'asian'\n",
    "rf_data.loc[rf_data['ethnicity'].str.contains('indian'), 'ethnicity'] = 'asian'\n",
    "rf_data.loc[rf_data[\"ethnicity\"].str.contains('hispanic / latin'), 'ethnicity'] = 'hispanic/latin'\n",
    "rf_data.loc[rf_data[\"ethnicity\"].str.contains('american'), 'ethnicity'] = 'american'\n",
    "rf_data.loc[rf_data[\"ethnicity\"].str.contains('native american'), 'ethnicity'] = 'american'\n",
    "rf_data.loc[rf_data['ethnicity'].str.contains('black'), 'ethnicity'] = 'american'\n",
    "rf_data.loc[rf_data[\"ethnicity\"].str.contains('pacific islander'), 'ethnicity'] = 'pacific islander'\n",
    "rf_data.loc[rf_data[\"ethnicity\"].str.contains('white'), 'ethnicity'] = 'american'\n",
    "rf_data.loc[rf_data[\"ethnicity\"].str.contains('middle eastern,'), 'ethnicity'] = 'middle eastern'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting different religions in wider buckets\n",
    "\n",
    "rf_data[\"religion\"] = rf_data[\"religion\"].fillna(\"other\")\n",
    "rf_data.loc[rf_data['religion'].str.contains('agnosticism'), 'religion'] = 'agnosticism'\n",
    "rf_data.loc[rf_data['religion'].str.contains('atheism'), 'religion'] = 'atheism'\n",
    "rf_data.loc[rf_data['religion'].str.contains('catholicism'), 'religion'] = 'catholicism'\n",
    "rf_data.loc[rf_data['religion'].str.contains('buddhism'), 'religion'] = 'buddhism'\n",
    "rf_data.loc[rf_data['religion'].str.contains('other'), 'religion'] = 'other'\n",
    "rf_data.loc[rf_data['religion'].str.contains('hinduism'), 'religion'] = 'hinduism'\n",
    "rf_data.loc[rf_data['religion'].str.contains('islam'), 'religion'] = 'islam'\n",
    "rf_data.loc[rf_data['religion'].str.contains('judaism'), 'religion'] = 'judaism'\n",
    "rf_data.loc[rf_data['religion'].str.contains('christianity'), 'religion'] = 'christianity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting different age in wider buckets\n",
    "\n",
    "# rf_data[\"age\"] = [\"less than 30\" if val<=30 else \" above 30\" for val in rf_data[\"age\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting different education classes in wider buckets\n",
    "\n",
    "\n",
    "rf_data[\"education\"] = rf_data[\"education\"].fillna('in college/university')\n",
    "rf_data.loc[rf_data['education'].str.contains(\"graduated\"), 'education'] = 'graduated'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"working\"), 'education'] = 'in college/university'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"two-year college\"), 'education'] = 'in college/university'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"masters program\"), 'education'] = 'in college/university'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"law school\"), 'education'] = 'in college/university'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"space camp\"), 'education'] = 'in college/university'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"ph.d program\"), 'education'] = 'in college/university'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"med school\"), 'education'] = 'in college/university'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"college/university\"), 'education'] = 'in college/university'\n",
    "rf_data.loc[rf_data['education'].str.contains(\"dropped out\"), 'education'] = 'dropped out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treating nans\n",
    "rf_data[\"drinks\"] = rf_data[\"drinks\"].fillna(\"not at all\")\n",
    "rf_data[\"smokes\"] = rf_data[\"smokes\"].fillna(\"no\")\n",
    "rf_data[\"smokes\"] = rf_data[\"smokes\"].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rf_data = rf_data\n",
    "cleaned_rf_data_dummified = pd.get_dummies(cleaned_rf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = cleaned_rf_data_dummified.loc[:,cleaned_rf_data_dummified.columns != \"drugs\"]\n",
    "\n",
    "\n",
    "y_rf = cleaned_rf_data_dummified.loc[:,cleaned_rf_data_dummified.columns == \"drugs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size = .10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = cleaned_rf_data_dummified['drugs'].value_counts()\n",
    "\n",
    "rf_class_0 = cleaned_rf_data_dummified[cleaned_rf_data_dummified['drugs'] == 0]\n",
    "rf_class_1 = cleaned_rf_data_dummified[cleaned_rf_data_dummified['drugs'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "1    37724\n",
      "0    37724\n",
      "Name: drugs, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_class_1_over = rf_class_1.sample(count_class_0, replace=True)\n",
    "rf_test_over = pd.concat([rf_class_0, rf_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(rf_test_over[\"drugs\"].value_counts())\n",
    "\n",
    "rf_test_over[\"drugs\"].value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_over = rf_test_over.loc[:, rf_test_over.columns != \"drugs\"]\n",
    "y_rf_over = rf_test_over.loc[:, rf_test_over.columns==\"drugs\"]\n",
    "X_rf_over_train, X_rf_over_test, y_rf_over_train, y_rf_over_test = train_test_split(X_rf_over, y_rf_over[\"drugs\"], test_size=0.10, random_state=1)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_rf_over_train, y_rf_over_train)\n",
    "y_rf_over_preds = model.predict(X_rf_over_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_model_report(y_rf_over_test, y_rf_over_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_preds = model.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(estimator, X, y):\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    acc = []\n",
    "    f1 = []\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "         \n",
    "        \n",
    "        X_test = X[test_idx]\n",
    "        y_test = y[test_idx]\n",
    "\n",
    "        # data prep\n",
    "        \n",
    "        estimator.fit(X_train, y_train)\n",
    "        y_preds = estimator.predict(X_test)\n",
    "        acc.append(accuracy_score(y_test, y_preds))\n",
    "        f1.append(f1_score(y_test, y_preds))\n",
    "    \n",
    "    generate_model_report(y_test, y_preds)\n",
    "        \n",
    "    plt.plot(range(0, 10), f1, label=estimator.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators = [RandomForestClassifier()]\n",
    "estimators = [LogisticRegression(max_iter=1000), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "for estimator in estimators:\n",
    "    run_model(estimator, X_rf_over.values, Y_rf_over[\"drugs\"].values)\n",
    "    \n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.xlabel('# of Folds', fontsize=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_rf_over_train, y_rf_over_train)\n",
    "y_final_preds = model.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance\n",
    "feat_scores = pd.DataFrame({'Fraction of Samples Affected' : model.feature_importances_},\n",
    "                           index=X_rf.columns)\n",
    "feat_scores = feat_scores.sort_values(by='Fraction of Samples Affected')\n",
    "feat_scores.plot(kind='barh')\n",
    "plt.title('RF Feature Importances - MDI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_report(y_actual, y_predicted):\n",
    "    print('Accuracy: %.3f' % accuracy_score(y_actual, y_predicted))\n",
    "    print('Precision: %.3f' % precision_score(y_actual, y_predicted))\n",
    "    print( 'Recall: %.3f' % recall_score(y_actual, y_predicted))\n",
    "    print('F1 score: %.3f' % f1_score(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def display_default_and_gsearch_model_results(model_default, model_gridsearch, \n",
    "                                              X_test, y_test):\n",
    "    '''\n",
    "        Parameters: model_default: fit model using initial parameters\n",
    "                    model_gridsearch: fit model using parameters from gridsearch\n",
    "                    X_test: 2d numpy array\n",
    "                    y_test: 1d numpy array\n",
    "        Return: None, but prints out mse and r2 for the default and model with\n",
    "                gridsearched parameters\n",
    "    '''\n",
    "    name = model_default.__class__.__name__.replace('Classifier', '') # for printing\n",
    "    y_test_pred = model_gridsearch.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"Results for {0}\".format(name))\n",
    "    print(\"Gridsearched model acc: {:0.3f}\".format(acc))\n",
    "    y_test_pred = model_default.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"     Default model acc: {:0.3f}\".format(acc))\n",
    "    \n",
    "    \n",
    "    \n",
    "def gridsearch_with_output(estimator, parameter_grid, X_train, y_train):\n",
    "    '''\n",
    "        Parameters: estimator: the type of model (e.g. RandomForestRegressor())\n",
    "                    paramter_grid: dictionary defining the gridsearch parameters\n",
    "                    X_train: 2d numpy array\n",
    "                    y_train: 1d numpy array\n",
    "        Returns:  best parameters and model fit with those parameters\n",
    "    '''\n",
    "    model_gridsearch = GridSearchCV(estimator,\n",
    "                                    parameter_grid,\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=True,\n",
    "                                    scoring='accuracy')\n",
    "    model_gridsearch.fit(X_train, y_train)\n",
    "    best_params = model_gridsearch.best_params_ \n",
    "    model_best = model_gridsearch.best_estimator_\n",
    "    print(\"\\nResult of gridsearch:\")\n",
    "    print(\"{0:<20s} | {1:<8s} | {2}\".format(\"Parameter\", \"Optimal\", \"Gridsearch values\"))\n",
    "    print(\"-\" * 55)\n",
    "    for param, vals in parameter_grid.items():\n",
    "        print(\"{0:<20s} | {1:<8s} | {2}\".format(str(param), \n",
    "                                                str(best_params[param]),\n",
    "                                                str(vals)))\n",
    "    return best_params, model_best\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.696\n",
      "Precision: 0.782\n",
      "Recall: 0.545\n",
      "F1 score: 0.643\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=500, max_depth=2, random_state=1, max_features=1, verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "gb.fit(X_rf_over_train, y_rf_over_train)\n",
    "y_rf_over_preds = model.predict(X_rf_over_test)\n",
    "generate_model_report(y_rf_over_test, y_rf_over_preds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.789\n",
      "Precision: 0.412\n",
      "Recall: 0.549\n",
      "F1 score: 0.471\n"
     ]
    }
   ],
   "source": [
    "y_final_preds = gb.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 26.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of gridsearch:\n",
      "Parameter            | Optimal  | Gridsearch values\n",
      "-------------------------------------------------------\n",
      "max_depth            | None     | [3, None]\n",
      "max_features         | sqrt     | ['sqrt', 'log2', None]\n",
      "min_samples_split    | 2        | [2, 4]\n",
      "min_samples_leaf     | 1        | [1, 2, 4]\n",
      "bootstrap            | True     | [True, False]\n",
      "n_estimators         | 10       | [10, 20, 40, 80]\n",
      "random_state         | 1        | [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 27.5min finished\n"
     ]
    }
   ],
   "source": [
    "random_forest_grid = {'max_depth': [3, None],\n",
    "                      'max_features': ['sqrt', 'log2', None],\n",
    "                      'min_samples_split': [2, 4],\n",
    "                      'min_samples_leaf': [1, 2, 4],\n",
    "                      'bootstrap': [True, False],\n",
    "                      'n_estimators': [10, 20, 40, 80],\n",
    "                      'random_state': [1]}\n",
    "rf_best_params, rf_best_model = gridsearch_with_output(RandomForestClassifier(), \n",
    "                                                       random_forest_grid, \n",
    "                                                       X_rf_over_train, y_rf_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.696\n",
      "Precision: 0.782\n",
      "Recall: 0.545\n",
      "F1 score: 0.643\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_features=\"sqrt\", min_samples_split=2, min_samples_leaf =1, bootstrap = True, n_estimators=10, random_state=1)\n",
    "\n",
    "rf.fit(X_rf_over_train, y_rf_over_train)\n",
    "y_rf_over_preds = model.predict(X_rf_over_test)\n",
    "generate_model_report(y_rf_over_test, y_rf_over_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.789\n",
      "Precision: 0.412\n",
      "Recall: 0.549\n",
      "F1 score: 0.471\n"
     ]
    }
   ],
   "source": [
    "y_final_preds = rf.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
