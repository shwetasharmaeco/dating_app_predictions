{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shwetasharma1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shwetasharma1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use(\"ggplot\")\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "np.random.seed(27)\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopwords_ = set(stopwords.words('english'))\n",
    "punctuation_ = set(string.punctuation)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer_snowball = SnowballStemmer('english')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer_porter = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diet column has more than half nans. will not be using it.\n",
    "#income had many negative values. dropping tyhis column as well\n",
    "\n",
    "\n",
    "users = pd.read_csv(\"./data/profiles.csv\")\n",
    "users_test = users[users[\"drugs\"].isna()]\n",
    "df = pd.read_csv(\"./users_essay\")\n",
    "# users_no_na = users[users[\"drugs\"].notna()]  commented out as this table was saved after cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "users_test[\"essay0\"] = users_test[\"essay0\"].fillna(\"\")\n",
    "users_test[\"essay1\"] = users_test[\"essay1\"].fillna(\"\")\n",
    "users_test[\"essay2\"] = users_test[\"essay2\"].fillna(\"\")\n",
    "users_test[\"essay3\"] = users_test[\"essay3\"].fillna(\"\")\n",
    "users_test[\"essay4\"] = users_test[\"essay4\"].fillna(\"\")\n",
    "users_test[\"essay5\"] = users_test[\"essay5\"].fillna(\"\")\n",
    "users_test[\"essay6\"] = users_test[\"essay6\"].fillna(\"\")\n",
    "users_test[\"essay7\"] = users_test[\"essay7\"].fillna(\"\")\n",
    "users_test[\"essay8\"] = users_test[\"essay8\"].fillna(\"\")\n",
    "users_test[\"essay9\"] = users_test[\"essay9\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# users_no_na[\"essay\"] = users_no_na[\"essay0\"] + users_no_na[\"essay1\"] + users_no_na[\"essay2\"] + users_no_na[\"essay3\"] + users_no_na[\"essay4\"] + users_no_na[\"essay5\"] + users_no_na[\"essay6\"] + users_no_na[\"essay7\"] + users_no_na[\"essay8\"] + users_no_na[\"essay9\"]\n",
    "\n",
    "users_test[\"essay\"] = users_test[\"essay0\"] + users_test[\"essay1\"] + users_test[\"essay2\"] + users_test[\"essay3\"] + users_test[\"essay4\"] + users_test[\"essay5\"] + users_test[\"essay6\"] + users_test[\"essay7\"] + users_test[\"essay8\"] + users_test[\"essay9\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    clean the text data: split the text, remove the redundant signs and words.\n",
    "    '''\n",
    "    text = text.replace('<br />', ' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    words = nltk.word_tokenize(text)   #split the text into words\n",
    "    words = [word for word in words if word.isalpha()]    #remove the non-alphabetic signs\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = [word for word in words if word not in set(stop_words)]   #remove the stop words\n",
    "    return words\n",
    "\n",
    "def clean_text_column(df, col_name):\n",
    "    '''\n",
    "    input a dataframe and one of its column, the function clean the text within\n",
    "    the column.\n",
    "    '''\n",
    "    df_ = df[df[col_name].notnull()]\n",
    "    df[col_name] = df_.apply(lambda row: clean_text(row[col_name]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_accents(input_str):\n",
    "    '''\n",
    "    This function is to remove the accents\n",
    "    '''\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode()\n",
    "\n",
    "def remove_http(sentences):\n",
    "    '''\n",
    "    remove the URLs in the text\n",
    "    '''\n",
    "    sentences_ = []\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "        sentences_.append(sentence)\n",
    "    return [sent for sent in sentences_ if not sent in {\"\", \"'\"}]\n",
    "\n",
    "def filter_tokens(sentence):\n",
    "    '''\n",
    "    This is to remove the stop words. Update the stop words in set stopwords2\n",
    "    '''\n",
    "    stopwords1 = set(stopwords.words('english'))\n",
    "    stopwords2 = {\"\\'s\",\"\\'ve\",\"\\'re\", \"n't\", 'INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "                  'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ', 'infj', 'entp','intp','intj',\n",
    "                  'entj','enfj','infp', 'enfp','isfp','istp','isfj','istj','estp','esfp','estj','esfj'}\n",
    "    stopwords_ = stopwords1.union(stopwords2)\n",
    "    \n",
    "    punctuation_ = set(string.punctuation)\n",
    "    return([w for w in sentence if not w in stopwords_ and not w in punctuation_])\n",
    "\n",
    "def remove_digits(sentences):\n",
    "    '''\n",
    "    remove the numbers in the text\n",
    "    '''\n",
    "    sentences_ = []\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub(r'[^a-zA-Z]+', ' ', sentence)\n",
    "        sentences_.append(sentence)\n",
    "    return [sent for sent in sentences_ if not sent in {\"\", \"'\"}]\n",
    "\n",
    "def lemm_and_stem(sentences):\n",
    "    '''\n",
    "    lemmatizing and stemming the words\n",
    "    '''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    output = []\n",
    "    for word_list in sentences:\n",
    "        lemmatized_words = [lemmatizer.lemmatize(w) for w in word_list]\n",
    "        stemmed_words = ' '.join([stemmer.stem(w) for w in lemmatized_words])\n",
    "        output.append(stemmed_words)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(input_str):\n",
    "    accent_removed=remove_accents(input_str) #remove the accent\n",
    "    sentences = accent_removed.split('|||') #split the string and get sentences\n",
    "    removed_http = remove_http(sentences)\n",
    "    removed_digits = remove_digits(removed_http)\n",
    "    tokens = [sent for sent in map(word_tokenize, removed_digits)]\n",
    "    tokens_lower = [[word.lower() for word in sentence]\n",
    "                 for sentence in tokens]\n",
    "    \n",
    "    tokens_filtered = list(map(filter_tokens, tokens_lower))\n",
    "    tokens_lemms = lemm_and_stem(tokens_filtered)\n",
    "\n",
    "    return tokens_lemms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(estimator, X, y):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    acc = []\n",
    "    f1 = []\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "         \n",
    "        \n",
    "        X_test = X[test_idx]\n",
    "        y_test = y[test_idx]\n",
    "\n",
    "        # data prep\n",
    "        \n",
    "        estimator.fit(X_train, y_train)\n",
    "        y_preds = estimator.predict(X_test)\n",
    "        acc.append(accuracy_score(y_test, y_preds))\n",
    "        f1.append(f1_score(y_test, y_preds))\n",
    "    \n",
    "    generate_model_report(y_test, y_preds)\n",
    "        \n",
    "    plt.plot(range(0, 5), f1, label=estimator.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_report(y_actual, y_predicted):\n",
    "    print('Accuracy: %.3f' % accuracy_score(y_actual, y_predicted))\n",
    "    print('Precision: %.3f' % precision_score(y_actual, y_predicted))\n",
    "    print( 'Recall: %.3f' % recall_score(y_actual, y_predicted))\n",
    "    print('F1 score: %.3f' % f1_score(y_actual, y_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# clean_text_column(users_no_na, 'essay')\n",
    "# users_no_na[\"essay\"] = users_no_na[\"essay\"].apply(lambda x: \", \".join(x))\n",
    " \n",
    "clean_text_column(users_test, 'essay')\n",
    "users_test[\"essay\"] = users_test[\"essay\"].apply(lambda x: \", \".join(x))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# users_no_na[\"essay\"]=  users_no_na[\"essay\"].apply(lambda x: clean_data(x))\n",
    "\n",
    "users_test[\"essay\"]=  users_test[\"essay\"].apply(lambda x: clean_data(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# users_no_na[\"essay\"] = users_no_na[\"essay\"].apply(lambda x: x[0] if x !=[] else \"\")\n",
    "\n",
    "\n",
    "users_test[\"essay\"] = users_test[\"essay\"].apply(lambda x: x[0] if x !=[] else \"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_test = pd.DataFrame(users_test)\n",
    "users_test.to_csv(\"users_test\")\n",
    "users_no_na = pd.DataFrame(users_no_na)\n",
    "users_no_na.to_csv(\"users_essay\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# rf_data = df[[\"age\", \"drinks\", \"education\", \"ethnicity\", \"orientation\", \"sex\", \"smokes\", \"religion\", \"drugs\", \"essay\"]]\n",
    "rf_data = df[[\"age\",\"drinks\",\"smokes\", \"drugs\"]]\n",
    "\n",
    "rf_data[\"drugs\"] = rf_data[\"drugs\"].replace([\"never\",\"sometimes\", \"often\"], [0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/shwetasharma1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#treating nans\n",
    "rf_data[\"drinks\"] = rf_data[\"drinks\"].fillna(\"not at all\")\n",
    "rf_data[\"smokes\"] = rf_data[\"smokes\"].fillna(\"no\")\n",
    "# rf_data[\"smokes\"] = rf_data[\"smokes\"].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_rf_data = rf_data[[\"age\", \"drinks\", \"education\", \"ethnicity\", \"orientation\", \"sex\", \"smokes\", \"religion\", \"drugs\"]]\n",
    "\n",
    "cleaned_rf_data = rf_data[[\"age\", \"drinks\", \"smokes\", \"drugs\"]]\n",
    "cleaned_rf_data_dummified = pd.get_dummies(cleaned_rf_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = cleaned_rf_data_dummified.loc[:,cleaned_rf_data_dummified.columns != \"drugs\"]\n",
    "\n",
    "\n",
    "y_rf = cleaned_rf_data_dummified.loc[:,cleaned_rf_data_dummified.columns == \"drugs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size = .10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = cleaned_rf_data_dummified['drugs'].value_counts()\n",
    "\n",
    "rf_class_0 = cleaned_rf_data_dummified[cleaned_rf_data_dummified['drugs'] == 0]\n",
    "rf_class_1 = cleaned_rf_data_dummified[cleaned_rf_data_dummified['drugs'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "1    37724\n",
      "0    37724\n",
      "Name: drugs, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_class_1_over = rf_class_1.sample(count_class_0, replace=True)\n",
    "rf_test_over = pd.concat([rf_class_0, rf_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(rf_test_over[\"drugs\"].value_counts())\n",
    "\n",
    "rf_test_over[\"drugs\"].value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_over = rf_test_over.loc[:, rf_test_over.columns != \"drugs\"]\n",
    "y_rf_over = rf_test_over.loc[:, rf_test_over.columns==\"drugs\"]\n",
    "X_rf_over_train, X_rf_over_test, y_rf_over_train, y_rf_over_test = train_test_split(X_rf_over, y_rf_over[\"drugs\"], test_size=0.10, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier (Round 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.704\n",
      "Precision: 0.786\n",
      "Recall: 0.562\n",
      "F1 score: 0.655\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_rf_over_train, y_rf_over_train)\n",
    "y_rf_over_preds = model.predict(X_rf_over_test)\n",
    "generate_model_report(y_rf_over_test, y_rf_over_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795\n",
      "Precision: 0.426\n",
      "Recall: 0.577\n",
      "F1 score: 0.490\n"
     ]
    }
   ],
   "source": [
    "y_final_preds = model.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grandient Boosting Classifier (Round 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784\n",
      "Precision: 0.408\n",
      "Recall: 0.580\n",
      "F1 score: 0.479\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_rf_over_train, y_rf_over_train)\n",
    "y_final_preds = model.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784\n",
      "Precision: 0.408\n",
      "Recall: 0.580\n",
      "F1 score: 0.479\n"
     ]
    }
   ],
   "source": [
    "y_final_preds = model.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def display_default_and_gsearch_model_results(model_default, model_gridsearch, \n",
    "                                              X_test, y_test):\n",
    "    '''\n",
    "        Parameters: model_default: fit model using initial parameters\n",
    "                    model_gridsearch: fit model using parameters from gridsearch\n",
    "                    X_test: 2d numpy array\n",
    "                    y_test: 1d numpy array\n",
    "        Return: None, but prints out mse and r2 for the default and model with\n",
    "                gridsearched parameters\n",
    "    '''\n",
    "    name = model_default.__class__.__name__.replace('Classifier', '') # for printing\n",
    "    y_test_pred = model_gridsearch.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"Results for {0}\".format(name))\n",
    "    print(\"Gridsearched model acc: {:0.3f}\".format(acc))\n",
    "    y_test_pred = model_default.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"     Default model acc: {:0.3f}\".format(acc))\n",
    "    \n",
    "    \n",
    "    \n",
    "def gridsearch_with_output(estimator, parameter_grid, X_train, y_train):\n",
    "    '''\n",
    "        Parameters: estimator: the type of model (e.g. RandomForestRegressor())\n",
    "                    paramter_grid: dictionary defining the gridsearch parameters\n",
    "                    X_train: 2d numpy array\n",
    "                    y_train: 1d numpy array\n",
    "        Returns:  best parameters and model fit with those parameters\n",
    "    '''\n",
    "    model_gridsearch = GridSearchCV(estimator,\n",
    "                                    parameter_grid,\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=True,\n",
    "                                    scoring='accuracy')\n",
    "    model_gridsearch.fit(X_train, y_train)\n",
    "    best_params = model_gridsearch.best_params_ \n",
    "    model_best = model_gridsearch.best_estimator_\n",
    "    print(\"\\nResult of gridsearch:\")\n",
    "    print(\"{0:<20s} | {1:<8s} | {2}\".format(\"Parameter\", \"Optimal\", \"Gridsearch values\"))\n",
    "    print(\"-\" * 55)\n",
    "    for param, vals in parameter_grid.items():\n",
    "        print(\"{0:<20s} | {1:<8s} | {2}\".format(str(param), \n",
    "                                                str(best_params[param]),\n",
    "                                                str(vals)))\n",
    "    return best_params, model_best\n",
    "\n",
    "\n",
    "http://localhost:8888/notebooks/feature_selection.ipynb#Gradient-Boosting-after-grid-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.700\n",
      "Precision: 0.776\n",
      "Recall: 0.564\n",
      "F1 score: 0.654\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=500, max_depth=2, random_state=1, max_features=1, verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "gb.fit(X_rf_over_train, y_rf_over_train)\n",
    "y_rf_over_preds = model.predict(X_rf_over_test)\n",
    "generate_model_report(y_rf_over_test, y_rf_over_preds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.785\n",
      "Precision: 0.410\n",
      "Recall: 0.583\n",
      "F1 score: 0.482\n"
     ]
    }
   ],
   "source": [
    "y_final_preds = gb.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   45.4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-a8974da68fc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m rf_best_params, rf_best_model = gridsearch_with_output(RandomForestClassifier(), \n\u001b[1;32m      9\u001b[0m                                                        \u001b[0mrandom_forest_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                                        X_rf_over_train, y_rf_over_train)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-207-617dbdb8d006>\u001b[0m in \u001b[0;36mgridsearch_with_output\u001b[0;34m(estimator, parameter_grid, X_train, y_train)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                     scoring='accuracy')\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mmodel_gridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmodel_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_forest_grid = {'max_depth': [3, None],\n",
    "                      'max_features': ['sqrt', 'log2', None],\n",
    "                      'min_samples_split': [2, 4],\n",
    "                      'min_samples_leaf': [1, 2, 4],\n",
    "                      'bootstrap': [True, False],\n",
    "                      'n_estimators': [10, 20, 40, 80],\n",
    "                      'random_state': [1]}\n",
    "rf_best_params, rf_best_model = gridsearch_with_output(RandomForestClassifier(), \n",
    "                                                       random_forest_grid, \n",
    "                                                       X_rf_over_train, y_rf_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.700\n",
      "Precision: 0.776\n",
      "Recall: 0.564\n",
      "F1 score: 0.654\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_features=\"sqrt\", min_samples_split=2, min_samples_leaf =1, bootstrap = True, n_estimators=10, random_state=1)\n",
    "\n",
    "rf.fit(X_rf_over_train, y_rf_over_train)\n",
    "y_rf_over_preds = model.predict(X_rf_over_test)\n",
    "generate_model_report(y_rf_over_test, y_rf_over_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795\n",
      "Precision: 0.427\n",
      "Recall: 0.580\n",
      "F1 score: 0.492\n"
     ]
    }
   ],
   "source": [
    "y_final_preds = rf.predict(X_rf_test)\n",
    "generate_model_report(y_rf_test, y_final_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
